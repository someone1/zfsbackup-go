// Copyright Â© 2016 Prateek Malhotra (someone1@gmail.com)
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in
// all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
// THE SOFTWARE.

package cmd

import (
	"context"
	"fmt"
	"strings"
	"time"

	"github.com/spf13/cobra"

	"github.com/someone1/zfsbackup-go/backends"
	"github.com/someone1/zfsbackup-go/backup"
	"github.com/someone1/zfsbackup-go/helpers"
)

var (
	jobInfo         helpers.JobInfo
	fullIncremental string
	maxUploadSpeed  uint64
	passphrase      []byte
)

// sendCmd represents the send command
var sendCmd = &cobra.Command{
	Use:     "send [flags] filesystem|volume|snapshot uri(s)",
	Short:   "send will backup of a ZFS volume similar to how the \"zfs send\" command works.",
	Long:    `send take a subset of the`,
	PreRunE: validateSendFlags,
	RunE: func(cmd *cobra.Command, args []string) error {
		helpers.AppLogger.Infof("Limiting the number of active files to %d", jobInfo.MaxFileBuffer)
		helpers.AppLogger.Infof("Limiting the number of parallel uploads to %d", jobInfo.MaxParallelUploads)
		helpers.AppLogger.Infof("Max Backoff Time will be %v", jobInfo.MaxBackoffTime)
		helpers.AppLogger.Infof("Max Upload Retry Time will be %v", jobInfo.MaxRetryTime)
		helpers.AppLogger.Infof("Upload Chunk Size will be %dMiB", jobInfo.UploadChunkSize)
		if jobInfo.EncryptKey != nil {
			helpers.AppLogger.Infof("Will be using encryption key for %s", jobInfo.EncryptTo)
		}

		if jobInfo.SignKey != nil {
			helpers.AppLogger.Infof("Will be signed from %s", jobInfo.SignFrom)
		}

		return backup.Backup(context.Background(), &jobInfo)
	},
}

func init() {
	RootCmd.AddCommand(sendCmd)

	// ZFS send command options
	sendCmd.Flags().BoolVarP(&jobInfo.Replication, "replication", "R", false, "See the -R flag on zfs send for more information")
	sendCmd.Flags().BoolVarP(&jobInfo.Deduplication, "deduplication", "D", false, "See the -D flag for zfs send for more information.")
	sendCmd.Flags().StringVarP(&jobInfo.IncrementalSnapshot.Name, "incremental", "i", "", "See the -i flag on zfs send for more information")
	sendCmd.Flags().StringVarP(&fullIncremental, "intermediary", "I", "", "See the -I flag on zfs send for more information")
	sendCmd.Flags().BoolVarP(&jobInfo.Properties, "properties", "p", false, "See the -p flag on zfs send for more information.")

	// Specific to download only
	sendCmd.Flags().Uint64Var(&jobInfo.VolumeSize, "volsize", 200, "the maximum size (in MiB) a volume should be before splitting to a new volume. Note: zfsbackup will try its best to stay close/under this limit but it is not garaunteed.")
	sendCmd.Flags().IntVar(&jobInfo.CompressionLevel, "compressionLevel", 6, "the compression level to use with the compressor. Valid values are between 1-9.")
	sendCmd.Flags().BoolVar(&jobInfo.Resume, "resume", false, "set this flag to true when you want to try and resume a previously cancled or failed backup. It is up to the caller to ensure the same command line arguments are provided between the original backup and the resumed one.")
	sendCmd.Flags().BoolVar(&jobInfo.Full, "full", false, "set this flag to take a full backup of the specified volume using the most recent snapshot.")
	sendCmd.Flags().BoolVar(&jobInfo.Incremental, "increment", false, "set this flag to do an incremental backup of the most recent snapshot from the most recent snapshot found in the target.")
	sendCmd.Flags().DurationVar(&jobInfo.FullIfOlderThan, "fullIfOlderThan", -1*time.Minute, "set this flag to do an incremental backup of the most recent snapshot from the most recent snapshot found in the target unless the it's been greater than the time specified in this flag, then do a full backup.")
	sendCmd.Flags().StringVar(&jobInfo.Compressor, "compressor", helpers.InternalCompressor, "specify to use the internal (parallel) gzip implementation or an external binary (e.g. gzip, bzip2, pigz, lzma, xz, etc.) Syntax must be similar to the gzip compression tool) to compress the stream for storage. Please take into consideration time, memory, and CPU usage for any of the compressors used. All manifests utilize the internal compressor. If value is zfs, the zfs stream will be created compressed. See the -c flag on zfs send for more information.")

	sendCmd.Flags().IntVar(&jobInfo.MaxFileBuffer, "maxFileBuffer", 5, "the maximum number of files to have active during the upload process. Should be set to at least the number of max parallel uploads. Set to 0 to bypass local storage and upload straight to your destination - this will limit you to a single destination and disable any hash checks for the upload where available.")
	sendCmd.Flags().IntVar(&jobInfo.MaxParallelUploads, "maxParallelUploads", 4, "the maximum number of uploads to run in parallel.")
	sendCmd.Flags().Uint64Var(&maxUploadSpeed, "maxUploadSpeed", 0, "the maximum upload speed (in KB/s) the program should use between all upload workers. Use 0 for no limit")
	sendCmd.Flags().DurationVar(&jobInfo.MaxRetryTime, "maxRetryTime", 12*time.Hour, "the maximum time that can elapse when retrying a failed upload. Use 0 for no limit.")
	sendCmd.Flags().DurationVar(&jobInfo.MaxBackoffTime, "maxBackoffTime", 30*time.Minute, "the maximum delay you'd want a worker to sleep before retrying an upload.")
	sendCmd.Flags().StringVar(&jobInfo.Separator, "separator", "|", "the separator to use between object component names.")
	sendCmd.Flags().IntVar(&jobInfo.UploadChunkSize, "uploadChunkSize", 10, "the chunk size, in MiB, to use when uploading. A minimum of 5MiB and maximum of 100MiB is enforced.")
}

// ResetSendJobInfo exists solely for integration testing
func ResetSendJobInfo() {
	resetRootFlags()
	// ZFS send command options
	jobInfo.Replication = false
	jobInfo.Deduplication = false
	jobInfo.IncrementalSnapshot = helpers.SnapshotInfo{}
	jobInfo.BaseSnapshot = helpers.SnapshotInfo{}
	fullIncremental = ""
	jobInfo.Properties = false

	// Specific to download only
	jobInfo.VolumeSize = 200
	jobInfo.CompressionLevel = 6
	jobInfo.Resume = false
	jobInfo.Full = false
	jobInfo.Incremental = false
	jobInfo.FullIfOlderThan = -1 * time.Minute

	jobInfo.MaxFileBuffer = 5
	jobInfo.MaxParallelUploads = 4
	maxUploadSpeed = 0
	jobInfo.MaxRetryTime = 12 * time.Hour
	jobInfo.MaxBackoffTime = 30 * time.Minute
	jobInfo.Separator = "|"
	jobInfo.UploadChunkSize = 10
	jobInfo.Compressor = helpers.InternalCompressor
}

func updateJobInfo(args []string) error {
	jobInfo.StartTime = time.Now()
	jobInfo.Version = helpers.VersionNumber

	if fullIncremental != "" {
		jobInfo.IncrementalSnapshot.Name = fullIncremental
		jobInfo.IntermediaryIncremental = true
	}

	parts := strings.Split(args[0], "@")
	jobInfo.VolumeName = parts[0]
	jobInfo.Destinations = strings.Split(args[1], ",")

	if len(jobInfo.Destinations) > 1 && jobInfo.MaxFileBuffer == 0 {
		helpers.AppLogger.Errorf("Specifying multiple destinations and a MaxFileBuffer size of 0 is unsupported.")
		return errInvalidInput
	}

	for _, destination := range jobInfo.Destinations {
		_, err := backends.GetBackendForURI(destination)
		if err == backends.ErrInvalidPrefix {
			helpers.AppLogger.Errorf("Unsupported prefix provided in destination URI, was given %s", destination)
			return err
		} else if err == backends.ErrInvalidURI {
			helpers.AppLogger.Errorf("Unsupported destination URI, was given %s", destination)
			return err
		}
	}

	// If we aren't using a "smart" option, rely on the user to provide the snapshots to use!
	if !jobInfo.Full && !jobInfo.Incremental && jobInfo.FullIfOlderThan == -1*time.Minute {
		if len(parts) != 2 {
			helpers.AppLogger.Errorf("Invalid base snapshot provided. Expected format <volume>@<snapshot>, got %s instead", args[0])
			return errInvalidInput
		}
		jobInfo.BaseSnapshot = helpers.SnapshotInfo{Name: parts[1]}
		creationTime, err := helpers.GetCreationDate(context.TODO(), args[0])
		if err != nil {
			helpers.AppLogger.Errorf("Error trying to get creation date of specified base snapshot - %v", err)
			return err
		}
		jobInfo.BaseSnapshot.CreationTime = creationTime

		if jobInfo.IncrementalSnapshot.Name != "" {
			jobInfo.IncrementalSnapshot.Name = strings.TrimPrefix(jobInfo.IncrementalSnapshot.Name, jobInfo.VolumeName)
			jobInfo.IncrementalSnapshot.Name = strings.TrimPrefix(jobInfo.IncrementalSnapshot.Name, "@")

			creationTime, err = helpers.GetCreationDate(context.TODO(), fmt.Sprintf("%s@%s", jobInfo.VolumeName, jobInfo.IncrementalSnapshot.Name))
			if err != nil {
				helpers.AppLogger.Errorf("Error trying to get creation date of specified incremental snapshot - %v", err)
				return err
			}
			jobInfo.IncrementalSnapshot.CreationTime = creationTime
		}
	} else {
		// Some basic checks here
		onlyOneCheck := 0
		if jobInfo.Full {
			onlyOneCheck++
		}
		if jobInfo.Incremental {
			onlyOneCheck++
		}
		if jobInfo.FullIfOlderThan != -1*time.Minute {
			onlyOneCheck++
		}
		if onlyOneCheck > 1 {
			helpers.AppLogger.Errorf("Please specify only one \"smart\" option at a time")
			return errInvalidInput
		}
		if len(parts) != 1 {
			helpers.AppLogger.Errorf("When using a smart option, please only specify the volume to backup, do not include any snapshot information.")
			return errInvalidInput
		}
		if err := backup.ProcessSmartOptions(context.Background(), &jobInfo); err != nil {
			helpers.AppLogger.Errorf("Error while trying to process smart option - %v", err)
			return err
		}
		helpers.AppLogger.Debugf("Utilizing smart option.")
	}

	return nil
}

func validateSendFlags(cmd *cobra.Command, args []string) error {
	if len(args) != 2 {
		cmd.Usage()
		return errInvalidInput
	}

	if jobInfo.IncrementalSnapshot.Name != "" && fullIncremental != "" {
		helpers.AppLogger.Errorf("The flags -i and -I are mutually exclusive. Please specify only one of these flags.")
		return errInvalidInput
	}

	if err := jobInfo.ValidateSendFlags(); err != nil {
		helpers.AppLogger.Error(err)
		return err
	}

	return updateJobInfo(args)
}
